{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Shivam Tyagi\n",
        "\n",
        "**Student ID**:  220428206\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Building a Machine Learning model which aims at predictng the exact indoor spot of a particular location.\n",
        "To clearly predict the exact indoor spot of the possible 2-3 spots per location, various features that an audio data posesses are explored and the models efficiency is tested using the acuuracy score along with confusion matrix.\n",
        "\n",
        "It is interesting because different indoors can have different type of noise levels which result in different audio features, for example campus curve would have more noise as compared to campus reception. Thus by using the location along with audio features we can train the classifier so that it can predict the spot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "1. **Data Load**: Loading the data files in .wav format from personal google drive.\n",
        "\n",
        "2. **Label Conversion**:  Converted the labels as 1 ,2 ,3 for the three types of indoor spots available for all the locations except southbank where only 2 indoor locations were present. \n",
        "\n",
        "3. **Feature Extraction**: Specific spectral features related to audio files such as: centroid, bandwidth, mfcc etc were extracted.\n",
        "\n",
        "4. **Component Analysis**: Following feature extraction, Principal component analysis was performed to take out only the most contributing features(3 in our case excluding the location, hence 4 input features).\n",
        "\n",
        "5. **Data split**: The whole dataset is then split into training and validation with 70:30 raito.\n",
        "\n",
        "6. **Standardisation**: The training and validation data is then normalized using mean and standard deviation, X = (X-mean)/sd.\n",
        "\n",
        "7. **ML Model**: Different ML models like SVC, RandomForest are trained and the best is selected according to point number 8, validation scores. \n",
        "\n",
        "8. **Validations**: Perfromance of the model is then judged on the basis of accuracy,precision, recall,f1 score and confusion matrix. All of the above are calculated for the training as well as validation datset. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n"
      ],
      "metadata": {
        "id": "moBjJ2vghWsf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3syE7HZkVd4",
        "outputId": "c262aa7e-33c9-41fc-c06f-57bbbc0e1e44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "directory_to_extract_to1 = '/content/drive/MyDrive/Data/MiniProject/sample1/'\n",
        "directory_to_extract_to2 = '/content/drive/MyDrive/Data/MiniProject/sample2/'\n",
        "directory_to_extract_to3 = '/content/drive/MyDrive/Data/MiniProject/sample3/'\n",
        "directory_to_extract_to4 = '/content/drive/MyDrive/Data/MiniProject/sample4/'\n",
        "directory_to_extract_to5 = '/content/drive/MyDrive/Data/MiniProject/sample5/'\n",
        "\n",
        "zip_path=[]\n",
        "zip_path1 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_1.zip'\n",
        "zip_path2 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_2.zip'\n",
        "zip_path3 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_3.zip'\n",
        "zip_path4 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_4.zip'\n",
        "zip_path5 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_5.zip'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_path1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to1)\n",
        "\n",
        "with zipfile.ZipFile(zip_path2, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to2)\n",
        "\n",
        "with zipfile.ZipFile(zip_path3, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to3)\n",
        "\n",
        "with zipfile.ZipFile(zip_path4, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to4)\n",
        "\n",
        "with zipfile.ZipFile(zip_path5, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to5)\n",
        "\n",
        "sample_path1 = '/content/drive/MyDrive/Data/MiniProject/sample1/*.wav'\n",
        "sample_path2 = '/content/drive/MyDrive/Data/MiniProject/sample2/*.wav'\n",
        "sample_path3 = '/content/drive/MyDrive/Data/MiniProject/sample3/*.wav'\n",
        "sample_path4 = '/content/drive/MyDrive/Data/MiniProject/sample4/*.wav'\n",
        "sample_path5 = '/content/drive/MyDrive/Data/MiniProject/sample5/*.wav'\n",
        "files1 = glob.glob(sample_path1)\n",
        "files2 = glob.glob(sample_path2)\n",
        "files3 = glob.glob(sample_path3)\n",
        "files4 = glob.glob(sample_path4)\n",
        "files5 = glob.glob(sample_path5)\n",
        "\n"
      ],
      "metadata": {
        "id": "YxMlvt_AhfSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "#Taking only the indoor spots from the whole csv\n",
        "MLENDLS_df = pd.read_csv('MLEndLS.csv').set_index('file_id') \n",
        "for i in range(0,len(MLENDLS_df)):\n",
        "  if MLENDLS_df['area'][i]==\"british\":\n",
        "    MLENDLS_df['area'][i]=1\n",
        "    if MLENDLS_df['spot'][i]==\"greatcourt\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"room12\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    elif MLENDLS_df['spot'][i]==\"room23\" or MLENDLS_df['spot'][i]==\"room13\":\n",
        "      MLENDLS_df['spot'][i]=3\n",
        "    else:\n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "  elif MLENDLS_df['area'][i]==\"campus\":\n",
        "    MLENDLS_df['area'][i]=2\n",
        "    if MLENDLS_df['spot'][i]==\"reception\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"curve\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    elif MLENDLS_df['spot'][i]==\"ground\":\n",
        "      MLENDLS_df['spot'][i]=3\n",
        "    else:\n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "  elif MLENDLS_df['area'][i]==\"westend\":\n",
        "    MLENDLS_df['area'][i]=3\n",
        "    if MLENDLS_df['spot'][i]==\"national\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"market\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    elif MLENDLS_df['spot'][i]==\"charing\":\n",
        "      MLENDLS_df['spot'][i]=3\n",
        "    else: \n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "  elif MLENDLS_df['area'][i]==\"southbank\":\n",
        "    MLENDLS_df['area'][i]=4\n",
        "    if MLENDLS_df['spot'][i]==\"royal\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"waterloo\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    else:\n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "  elif MLENDLS_df['area'][i]==\"kensington\":\n",
        "    MLENDLS_df['area'][i]=5\n",
        "    if MLENDLS_df['spot'][i]==\"dinosaur\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"hintze\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    elif MLENDLS_df['spot'][i]==\"marine\":\n",
        "      MLENDLS_df['spot'][i]=3\n",
        "    else: \n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "  elif MLENDLS_df['area'][i]==\"Euston\":\n",
        "    MLENDLS_df['area'][i]=6\n",
        "    if MLENDLS_df['spot'][i]==\"upper\":\n",
        "      MLENDLS_df['spot'][i]=1\n",
        "    elif MLENDLS_df['spot'][i]==\"library\":\n",
        "      MLENDLS_df['spot'][i]=2\n",
        "    elif MLENDLS_df['spot'][i]==\"ritblat\":\n",
        "      MLENDLS_df['spot'][i]=3\n",
        "    else: \n",
        "      MLENDLS_df['spot'][i]='Nan'\n",
        "\n",
        "df=MLENDLS_df.drop(MLENDLS_df[MLENDLS_df['spot'] == \"Nan\"].index)"
      ],
      "metadata": {
        "id": "lrV27FuXmt1H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "Three types of transformations have been done:\n",
        "1. **Output Label Conversions**:\n",
        "\n",
        "*   As we are interested in checking that if the audio was recorded at a particular spot of a location hence we have three classes to predict per location because for all the locations we have 3 different indoor spots except southbank where we have 2 of indoor sports.\n",
        "\n",
        "*   We assign the value of labels as 1,2,3 for all the indoor spots for all location and we assign 1,2 for the indoor spots of southbank, by doing so we have converted the labels from categorical data to numeric data and hence easy to understand for most of the ML models.\n",
        "\n",
        "2. **Feature Extraction**:\n",
        "\n",
        "*   Different indoor places will definitely have different noise levels, for example campus curve would be noisier than campus reception hence spectral features like bandwidth, centroid, flatness and zero crossing rates are chosen which will have a higher value for for certain spots(noisier) as compared to other quiet places.\n",
        "\n",
        "*   MFCC is used for audio similarity measures which will give similar outputs for similar type of audios.\n",
        "\n",
        "\n",
        "3. **Input Feature Conversions**:\n",
        "\n",
        "\n",
        "*   As all the features exctracted are in the form of numpy array hence  taking their mean and then they are given as input lables which would then be used as inputs to the classifier.\n",
        "*   Not all the features would be contributing as desired, hence Principal Component Analysis is performed on these input labels, value of the number of components is increased until the highest accuracy is acheived.\n",
        "*   PCA with number of components =3 gives the highest accuracy.\n",
        "\n",
        "*   Also as we need to predict the spot of a particular location hence we need to keep the location column which has values from 1 to 6. So PCA is performed on all other columns and 3 best are selected as they gave higher accuracy.\n",
        "*   So finally we have 4 input features which we use as the inputs to the classifier, one is location and the rest 3 are from PCA.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "def getPitch(x,fs,winLen=0.02):\n",
        "  #winLen = 0.02 \n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
        "                                                 frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag"
      ],
      "metadata": {
        "id": "30Mlwu5ohNGk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "def getXy(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    file_name = file.split('/')[-1]\n",
        "    if fileID in labels_file.index: #Using only the files with indoor spots according to the csv which now have only indoor spots\n",
        "      yi = labels_file.loc[fileID]['spot']\n",
        "\n",
        "      fs = None # if None, fs would be 22050\n",
        "      x, fs = librosa.load(file,sr=fs)\n",
        "      mfcc = librosa.feature.mfcc(y = x, sr = fs, hop_length=513, n_mfcc=13) #for audio similarity measures\n",
        "      cent = librosa.feature.spectral_centroid(y=x, sr=fs)\n",
        "      spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=fs)\n",
        "      S = np.abs(librosa.stft(x))\n",
        "      contrast = librosa.feature.spectral_contrast(S=S, sr=fs)\n",
        "      flatness = librosa.feature.spectral_flatness(y=x)\n",
        "      zrcr=librosa.feature.zero_crossing_rate(x)\n",
        "    \n",
        "      if scale_audio: x = x/np.max(np.abs(x))\n",
        "      f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "      \n",
        "      power = np.sum(x**2)/len(x)\n",
        "      pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "      pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "      voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "      xi = [labels_file.loc[fileID]['area'],power,pitch_mean,pitch_std,voiced_fr,np.mean(mfcc),np.mean(cent),np.mean(spec_bw),np.mean(contrast),np.mean(flatness),np.mean(zrcr)]\n",
        "      X.append(xi)\n",
        "      y.append(yi)\n",
        "\n",
        "  return np.array(X),np.array(y)"
      ],
      "metadata": {
        "id": "OqPJ2aN4DpGD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "X1,y1 = getXy(files1, labels_file=df, scale_audio=True, onlySingleDigit=True)\n",
        "X2,y2 = getXy(files2, labels_file=df, scale_audio=True, onlySingleDigit=True)\n",
        "X3,y3 = getXy(files3, labels_file=df, scale_audio=True, onlySingleDigit=True)\n",
        "X4,y4 = getXy(files4, labels_file=df, scale_audio=True, onlySingleDigit=True)\n",
        "X5,y5 = getXy(files5, labels_file=df, scale_audio=True, onlySingleDigit=True)\n",
        "\n",
        "X=np.append(X1,X2,axis=0)\n",
        "X=np.append(X,X3,axis=0)\n",
        "X=np.append(X,X4,axis=0)\n",
        "X=np.append(X,X5,axis=0)\n",
        "\n",
        "y=np.append(y1,y2,axis=0)\n",
        "y=np.append(y,y3,axis=0)\n",
        "y=np.append(y,y4,axis=0)\n",
        "y=np.append(y,y5,axis=0)\n",
        "\n",
        "ys=pd.DataFrame(y)\n",
        "ys.to_csv(\"Label.csv\")\n",
        "\n",
        "Z=pd.DataFrame(X)\n",
        "Z.to_csv(\"Features.csv\")"
      ],
      "metadata": {
        "id": "ggVcT2Guh07a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from here after importing libraries, as up till now after extracting the features the csv is converetd and i am providing the same\n",
        "Z=pd.read_csv(\"Features_advanced.csv\")\n",
        "Z.drop(Z.columns[0], axis=1, inplace=True)\n",
        "\n",
        "ar=np.array(Z['0'])\n",
        "ar.ravel()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar = StandardScaler()\n",
        "scalar.fit(Z.iloc[ : , 1:])\n",
        "scaled_data = scalar.transform(Z.iloc[ : , 1:])\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "pca.fit(scaled_data)\n",
        "\n",
        "x_pca = pca.transform(scaled_data)\n",
        "\n",
        "X=np.array(x_pca)\n",
        "X=np.column_stack((X,ar))\n",
        "ys=pd.read_csv(\"Label_advanced.csv\")\n",
        "ys.drop(ys.columns[0], axis=1, inplace=True)\n",
        "y=np.array(ys)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "y=y.ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqHsrynMPICg",
        "outputId": "762c5341-02ff-4e5e-8249-b06540f7ca32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1176, 4)\n",
            "(1176, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "1. **SVM**: SVM SVC classifier is trained because it is majorly used for the data which does not have a known distribution i.e., audio data in our case. Also it does not suffer overfitting and have very effect of outliers which may be some audios with huge amount of noise indoors at a spot at a different point of time and hence could have caused issues in prediction. It gave the best results with cost parameter =2.\n",
        "\n",
        "2. **Random Forest Classifier**: Random Forest Classifier was trained as it handles non-linearity of parameters effeiciently, and also like SVM it is also robust to outlier. But it is not chosen because it was overfitting with incresing n_estimators used(10,20,30) on the training dataset, without any significant change in the validation accuracy, whcih can be checked if \"Rand\" is given as choice in below code.\n",
        "\n",
        "3. **KNeighbour Classifier**: It was trained as through KNN new data can be added seamlessly which will not impact the accuracy of the algorithm. The KNN model has ben used with n_neighbors=[5, 10, 50]. As 70% of the data (800+) is used for training the data, so about 274 data rows were present for each class while training. But it was not chosen because of lower accuracy than SVM.\n",
        "\n",
        "At last SVM was chosen because of higher accuracy on validation datset with cost parameter value as 2 and without any overfitting on the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3,random_state=10)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
        "\n",
        "choice=\"Svc\"\n",
        "\n",
        "if choice==\"Rand\":\n",
        "  print(\"RandomForest:\")\n",
        "  model  = RandomForestClassifier(n_estimators=10)\n",
        "elif choice==\"Svc\":\n",
        "  print(\"SVC:\")\n",
        "  model  = svm.SVC(C=2)\n",
        "else:\n",
        "    print(\"KNN\")\n",
        "    model=KNeighborsClassifier(n_neighbors=50) \n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "9lM4V8Wlo4Ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bbdae9-1feb-4f3e-bed2-2c0858f1d118"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "The model training is already explianed in the previous section.\n",
        "\n",
        "Performance of the modles were accessed through the following:\n",
        "\n",
        "1. Accuracy: Accuracy is the ratio of correct predictions out of all predictions made by an algorithm. It can be calculated by dividing precision by recall or as 1 minus false negative rate (FNR) divided by false positive rate (FPR).\n",
        "2. Precision: The Precision is the ratio of true positives over the sum of false positives and true negatives. It is also known as positive predictive value.\n",
        "3. Recall: Recall is the ratio of correctly predicted outcomes to all predictions. It is also known as sensitivity or specificity.\n",
        "4. f1 score: The F1-score combines these three metrics into one single metric that ranges from 0 to 1 and it takes into account both Precision and Recall.\n",
        "5. Confusion matrix: This matrix tell us all the correctly clasified along with incorrectly classified labels in the form of a matrix hence easier to read.\n",
        "\n",
        "All of the above were kept into account while chosing the final classifier and their results were compared. SVM got the highest score for them all and hence was chose to finally train the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "1. 2487 audio files have been used in total out of which 1176 are outdoors and 1311 are indoors.\n",
        "2. Input features and output label conversion is done for all the files already explained earlier which is then followed by PCA to select only relevant input features.\n",
        "3. The total files are then divided into 70:30 raito for training and test data split. \n",
        "4. The 70% data is then used to train the classifier and the remaining 30% used to validate the classifier.\n",
        "\n",
        "All the code for feature extraction, label conversion and data split is already done in above sections and explained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "pt=precision_score(yt_p,y_train,average=\"weighted\")\n",
        "rt=recall_score(yt_p,y_train,average=\"weighted\")\n",
        "f1t=f1_score(yt_p,y_train,average=\"weighted\")\n",
        "mt=metrics.confusion_matrix(yt_p,y_train)\n",
        "\n",
        "\n",
        "pv=precision_score(yv_p,y_val,average=\"weighted\")\n",
        "rv=recall_score(yv_p,y_val,average=\"weighted\")\n",
        "f1v=f1_score(yv_p,y_val,average=\"weighted\")\n",
        "mv=metrics.confusion_matrix(yv_p,y_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train),\"\\nTraining precision\",pt,\"\\nTraining recall\",rt,\"\\nTrianing f1 score\",f1t)\n",
        "print(\"Confusion Matrix for training period:\",mt,\"\\n\")\n",
        "\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val),\"\\nValidation precision\",pv,\"\\nValidation recall\",rv,\"\\nValidation f1 score\",f1v)\n",
        "print(\"Confusion Matrix for validation period:\",mv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvHoBSf8abW-",
        "outputId": "d3186b7a-28bc-4eab-dac6-eab6923b2a99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.6646415552855407 \n",
            "Training precision 0.7459384881605963 \n",
            "Training recall 0.6646415552855407 \n",
            "Trianing f1 score 0.6869594271173859\n",
            "Confusion Matrix for training period: [[238  51  41]\n",
            " [ 54 246 111]\n",
            " [  7  12  63]] \n",
            "\n",
            "Validation  Accuracy 0.5694050991501416 \n",
            "Validation precision 0.645318922087578 \n",
            "Validation recall 0.5694050991501416 \n",
            "Validation f1 score 0.596360867531298\n",
            "Confusion Matrix for validation period: [[97 18 21]\n",
            " [23 87 60]\n",
            " [ 9 21 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(X_train,axis=0)\n",
        "sd=np.std(X_train,axis=0)\n",
        "X_train = (X_train-mean)/sd\n",
        "X_val  = (X_val-mean)/sd\n",
        "\n",
        "choice=\"Svc\"\n",
        "if choice==\"Rand\":\n",
        "  print(\"RandomForest:\")\n",
        "  model  = RandomForestClassifier()\n",
        "elif choice==\"Svc\":\n",
        "  print(\"SVC:\")\n",
        "  model  = svm.SVC(C=2)\n",
        "elif choice==\"Log\": \n",
        "  print(\"Logistic Regression Accuracy:\")\n",
        "  model  = LogisticRegression()\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "pt=precision_score(yt_p,y_train,average=\"weighted\")\n",
        "rt=recall_score(yt_p,y_train,average=\"weighted\")\n",
        "f1t=f1_score(yt_p,y_train,average=\"weighted\")\n",
        "mt=metrics.confusion_matrix(yt_p,y_train)\n",
        "\n",
        "\n",
        "pv=precision_score(yv_p,y_val,average=\"weighted\")\n",
        "rv=recall_score(yv_p,y_val,average=\"weighted\")\n",
        "f1v=f1_score(yv_p,y_val,average=\"weighted\")\n",
        "mv=metrics.confusion_matrix(yv_p,y_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train),\"\\nTraining precision\",pt,\"\\nTraining recall\",rt,\"\\nTrianing f1 score\",f1t)\n",
        "print(\"Confusion Matrix for training period:\",mt,\"\\n\")\n",
        "\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val),\"\\nValidation precision\",pv,\"\\nValidation recall\",rv,\"\\nValidation f1 score\",f1v)\n",
        "print(\"Confusion Matrix for validation period:\",mv)"
      ],
      "metadata": {
        "id": "BtruWxeq9eXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985b2909-3b2e-42ac-d8e2-ee0dbbee5ad8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC:\n",
            "Training Accuracy 0.6646415552855407 \n",
            "Training precision 0.7459384881605963 \n",
            "Training recall 0.6646415552855407 \n",
            "Trianing f1 score 0.6869594271173859\n",
            "Confusion Matrix for training period: [[238  51  41]\n",
            " [ 54 246 111]\n",
            " [  7  12  63]] \n",
            "\n",
            "Validation  Accuracy 0.5694050991501416 \n",
            "Validation precision 0.645318922087578 \n",
            "Validation recall 0.5694050991501416 \n",
            "Validation f1 score 0.596360867531298\n",
            "Confusion Matrix for validation period: [[97 18 21]\n",
            " [23 87 60]\n",
            " [ 9 21 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "After training different models and comparing their effeciency through the defined metrices SVM was found out to be the best.\n",
        "\n",
        "Classes 1 and 2 were predicted correctly more number of time, class 2 and 3 shows some confusion among themselves which means that these indoor spots have less difference in noise.\n",
        "\n",
        "The confusion between class 1 and class 3 of all the locations is high, which mean that these spots have more difference in noise than between any other combination.\n",
        "\n",
        "The scores of the best model i.e., SVM for predicting an audio as indoors or outdoors are as follows:\n",
        "\n",
        "SVC:\n",
        "\n",
        "Training Accuracy 0.6646415552855407 \n",
        "\n",
        "Training precision 0.7459384881605963 \n",
        "\n",
        "Training recall 0.6646415552855407 \n",
        "\n",
        "Trianing f1 score 0.6869594271173859\n",
        "\n",
        "Confusion Matrix for training period: \n",
        "\n",
        "[[238  51  41]\n",
        "\n",
        "[ 54 246 111]\n",
        "\n",
        "[  7  12  63]] \n",
        "\n",
        "Validation  Accuracy 0.5694050991501416 \n",
        "\n",
        "Validation precision 0.645318922087578 \n",
        "\n",
        "Validation recall 0.5694050991501416 \n",
        "\n",
        "Validation f1 score 0.596360867531298\n",
        "\n",
        "Confusion Matrix for validation period: \n",
        "\n",
        "[[97 18 21]\n",
        "\n",
        "[23 87 60]\n",
        " \n",
        "[ 9 21 17]]"
      ]
    }
  ]
}
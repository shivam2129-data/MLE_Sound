{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Shivam Tyagi\n",
        "\n",
        "**Student ID**:  220428206\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Building a Machine Learning model which aims at predictng whether an audio is recorded indoors or outdoors.To clearly predict the location type whether indoors or outdoors, various features that an audio data posesses are explored and the models efficiency is tested using the acuuracy score along with confusion matrix.\n",
        "\n",
        "It is interesting because by using only few locations we can train the classifier so that it can predict whether or not any recording is outdoor or indoor, irrespective of the location in future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "1. **Data Load**: Loading the data files in .wav format from personal google drive.\n",
        "\n",
        "2. **Label Conversion**:  Converted the labels as 0(outdoors) and 1(indoors). \n",
        "\n",
        "3. **Feature Extraction**: Specific spectral features related to audio files such as: centroid, bandwidth, mfcc etc were extracted.\n",
        "\n",
        "4. **Component Analysis**: Following feature extraction, Principal component analysis was performed to take out only the most contributing features(8 in our case).\n",
        "\n",
        "5. **Data split**: The whole dataset is then split into training and validation with 70:30 raito.\n",
        "\n",
        "6. **Standardisation**: The training and validation data is then normalized using mean and standard deviation, X = (X-mean)/sd.\n",
        "\n",
        "7. **ML Model**: Different ML models like SVC, RandomForest are trained and the best is selected according to point number 8, validation scores. \n",
        "\n",
        "8. **Validations**: Perfromance of the model is then judged on the basis of accuracy,precision, recall,f1 score and confusion matrix. All of the above are calculated for the training as well as validation datset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**\n",
        "\n",
        "There are few cells which does not require to be run as these are:\n",
        "1. Connected to my personal google drive and hence there would be problem while granting permission.\n",
        "2. It will take a lot of time to run all the 2500 file again.\n",
        "\n",
        "Hence I have run the cells, extracted the required features and then converted them to csv instead of running and loading the cells again and again and waiting for them to try anything new.\n",
        "\n",
        "Thus requesting to use the csv of the features and labels that i am providing along with the notebook to run and check the code.\n",
        "\n",
        "I would write a coment at top of each cell which is not required to be run."
      ],
      "metadata": {
        "id": "rTvC4IYNtWkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "moBjJ2vghWsf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGOAVpbmkZj0",
        "outputId": "ecc502c6-e0e8-468b-fead-8fcbfcca939a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "directory_to_extract_to1 = '/content/drive/MyDrive/Data/MiniProject/sample1/'\n",
        "directory_to_extract_to2 = '/content/drive/MyDrive/Data/MiniProject/sample2/'\n",
        "directory_to_extract_to3 = '/content/drive/MyDrive/Data/MiniProject/sample3/'\n",
        "directory_to_extract_to4 = '/content/drive/MyDrive/Data/MiniProject/sample4/'\n",
        "directory_to_extract_to5 = '/content/drive/MyDrive/Data/MiniProject/sample5/'\n",
        "\n",
        "zip_path=[]\n",
        "zip_path1 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_1.zip'\n",
        "zip_path2 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_2.zip'\n",
        "zip_path3 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_3.zip'\n",
        "zip_path4 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_4.zip'\n",
        "zip_path5 = '/content/drive/MyDrive/Data/MiniProject/MLEndLS_5.zip'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_path1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to1)\n",
        "\n",
        "with zipfile.ZipFile(zip_path2, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to2)\n",
        "\n",
        "with zipfile.ZipFile(zip_path3, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to3)\n",
        "\n",
        "with zipfile.ZipFile(zip_path4, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to4)\n",
        "\n",
        "with zipfile.ZipFile(zip_path5, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to5)\n",
        "\n",
        "sample_path1 = '/content/drive/MyDrive/Data/MiniProject/sample1/*.wav'\n",
        "sample_path2 = '/content/drive/MyDrive/Data/MiniProject/sample2/*.wav'\n",
        "sample_path3 = '/content/drive/MyDrive/Data/MiniProject/sample3/*.wav'\n",
        "sample_path4 = '/content/drive/MyDrive/Data/MiniProject/sample4/*.wav'\n",
        "sample_path5 = '/content/drive/MyDrive/Data/MiniProject/sample5/*.wav'\n",
        "files1 = glob.glob(sample_path1)\n",
        "files2 = glob.glob(sample_path2)\n",
        "files3 = glob.glob(sample_path3)\n",
        "files4 = glob.glob(sample_path4)\n",
        "files5 = glob.glob(sample_path5)\n",
        "\n",
        "MLENDLS_df = pd.read_csv('MLEndLS.csv').set_index('file_id') \n",
        "MLENDLS_df1=MLENDLS_df[0:497]\n",
        "MLENDLS_df2=MLENDLS_df[497:997]\n",
        "MLENDLS_df3=MLENDLS_df[997:1497]\n",
        "MLENDLS_df4=MLENDLS_df[1497:1997]\n",
        "MLENDLS_df5=MLENDLS_df[1997:2500] \n"
      ],
      "metadata": {
        "id": "YxMlvt_AhfSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "Three types of transformations have been done:\n",
        "1. **Output Label Conversions**:\n",
        "\n",
        "*   As we are interested only in checking that if the audio was recorded outdoors or indoors hence we have just two classes to predict.\n",
        "\n",
        "*   We assign the value of labels as 1 for indoors and 0 for outdoors, by doing so we have converted the labels from categorical data to numeric data and hence easy to understand for most of the ML models.\n",
        "\n",
        "2. **Feature Extraction**:\n",
        "\n",
        "*   Any outdoor recording will be more noisy compared to an indoor one hence spectral features like bandwidth, centroid, flatness and zero crossing rates are chosen which will have a higher value for outdoors as compared to indoors.\n",
        "*   Other features such as pitch, power are also used which are more prevelant for outdoor audios.\n",
        "\n",
        "*   MFCC is used for audio similarity measures which will give similar outputs for similar type of audios.\n",
        "\n",
        "\n",
        "3. **Input Feature Conversions**:\n",
        "\n",
        "\n",
        "*   As all the features exctracted are in the form of numpy array hence  taking their mean and then they are given as input lables which would then be used as inputs to the classifier.\n",
        "*   Not all the features would be contributing as desired, hence Principal Component Analysis is performed on these input labels, value of the number of components is increased until the highest accuracy is acheived.\n",
        "\n",
        "*   PCA with number of components =8 gives the highest accuracy and hence giving those as the inputs to the classifier.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "def getPitch(x,fs,winLen=0.02):\n",
        "  #winLen = 0.02 \n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
        "                                                 frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag"
      ],
      "metadata": {
        "id": "30Mlwu5ohNGk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "def getXy(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    file_name = file.split('/')[-1]\n",
        "    yi = labels_file.loc[fileID]['in_out']=='indoor'\n",
        "\n",
        "    fs = None # if None, fs would be 22050\n",
        "    x, fs = librosa.load(file,sr=fs)\n",
        "    mfcc = librosa.feature.mfcc(y = x, sr = fs, hop_length=513, n_mfcc=13) #for audio similarity measures\n",
        "    cent = librosa.feature.spectral_centroid(y=x, sr=fs)\n",
        "    spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=fs)\n",
        "    S = np.abs(librosa.stft(x))\n",
        "    contrast = librosa.feature.spectral_contrast(S=S, sr=fs)\n",
        "    flatness = librosa.feature.spectral_flatness(y=x)\n",
        "    zrcr=librosa.feature.zero_crossing_rate(x)\n",
        "    \n",
        "    if scale_audio: x = x/np.max(np.abs(x))\n",
        "    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "      \n",
        "    power = np.sum(x**2)/len(x)\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    xi = [power,pitch_mean,pitch_std,voiced_fr,np.mean(mfcc),np.mean(cent),np.mean(spec_bw),np.mean(contrast),np.mean(flatness),np.mean(zrcr)]\n",
        "    X.append(xi)\n",
        "    y.append(yi)\n",
        "\n",
        "  return np.array(X),np.array(y)"
      ],
      "metadata": {
        "id": "OqPJ2aN4DpGD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run only to verify\n",
        "X1,y1 = getXy(files1, labels_file=MLENDLS_df, scale_audio=True, onlySingleDigit=True)\n",
        "X2,y2 = getXy(files2, labels_file=MLENDLS_df2, scale_audio=True, onlySingleDigit=True)\n",
        "X3,y3 = getXy(files3, labels_file=MLENDLS_df3, scale_audio=True, onlySingleDigit=True)\n",
        "X4,y4 = getXy(files4, labels_file=MLENDLS_df4, scale_audio=True, onlySingleDigit=True)\n",
        "X5,y5 = getXy(files5, labels_file=MLENDLS_df5, scale_audio=True, onlySingleDigit=True)\n",
        "X=np.append(X1,X2,axis=0)\n",
        "X=np.append(X,X3,axis=0)\n",
        "X=np.append(X,X4,axis=0)\n",
        "X=np.append(X,X5,axis=0)\n",
        "\n",
        "y=np.append(y1,y2,axis=0)\n",
        "y=np.append(y,y3,axis=0)\n",
        "y=np.append(y,y4,axis=0)\n",
        "y=np.append(y,y5,axis=0)\n",
        "\n",
        "ys=pd.DataFrame(y)\n",
        "ys.to_csv(\"Label.csv\")\n",
        "\n",
        "Z=pd.DataFrame(X)\n",
        "Z.to_csv(\"Features.csv\")"
      ],
      "metadata": {
        "id": "ggVcT2Guh07a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from here after importing libraries, as up till now after extracting the features the csv is converetd and i am providing the same \n",
        "Z=pd.read_csv(\"Features.csv\")\n",
        "Z.drop(Z.columns[0], axis=1, inplace=True)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar = StandardScaler()\n",
        "scalar.fit(Z)\n",
        "scaled_data = scalar.transform(Z)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 8)\n",
        "pca.fit(scaled_data)\n",
        "\n",
        "x_pca = pca.transform(scaled_data)\n",
        "\n",
        "X=np.array(x_pca)\n",
        "ys=pd.read_csv(\"Label.csv\")\n",
        "ys.drop(ys.columns[0], axis=1, inplace=True)\n",
        "y=np.array(ys)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "y=y.ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqHsrynMPICg",
        "outputId": "ac4fb7ec-444b-477d-f30b-2ad7284ade30"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2487, 8)\n",
            "(2487, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "1. **SVM**: SVM SVC classifier is trained because it is majorly used for the data which does not have a known distribution i.e., audio data in our case. Also it does not suffer overfitting and have very effect of outliers which may be some audios with huge amount of noise indoors as well in our case and hence could have caused issues in prediction. It gave the best results with cost parameter =2.\n",
        "\n",
        "2. **Random Forest Classifier**: Random Forest Classifier was trained as it handles non-linearity of parameters effeiciently, and also like SVM it is also robust to outlier. But it is not chosen because it was overfitting with incresing n_estimators used(10,20,30) on the training dataset, without any significant change in the validation accuracy, whcih can be checked if \"Rand\" is given as choice in below code.\n",
        "\n",
        "3. **KNeighbour Classifier**: It was trained as through KNN new data can be added seamlessly which will not impact the accuracy of the algorithm. The KNN model has ben used with n_neighbors=[5, 10, 50]. As 70% of the data (1700+) is used for training the data, so about 850 data rows were present for each class while training. But it was not chosen because of lower accuracy than SVM.\n",
        "\n",
        "At last SVM was chosen because of higher accuracy on validation datset with cost parameter value as 2 and without any overfitting on the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3,random_state=10)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
        "\n",
        "choice=\"Svc\"\n",
        "\n",
        "if choice==\"Rand\":\n",
        "  print(\"RandomForest:\")\n",
        "  model  = RandomForestClassifier(n_estimators=10)\n",
        "elif choice==\"Svc\":\n",
        "  print(\"SVC:\")\n",
        "  model  = svm.SVC(C=2)\n",
        "else:\n",
        "    print(\"KNN\")\n",
        "    model=KNeighborsClassifier(n_neighbors=50) \n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "9lM4V8Wlo4Ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0df02f7-637c-467b-9bc5-c5c19c6dc6b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "The model training is already explianed in the previous section.\n",
        "\n",
        "Performance of the modles were accessed through the following:\n",
        "\n",
        "1. Accuracy: Accuracy is the ratio of correct predictions out of all predictions made by an algorithm. It can be calculated by dividing precision by recall or as 1 minus false negative rate (FNR) divided by false positive rate (FPR).\n",
        "2. Precision: The Precision is the ratio of true positives over the sum of false positives and true negatives. It is also known as positive predictive value.\n",
        "3. Recall: Recall is the ratio of correctly predicted outcomes to all predictions. It is also known as sensitivity or specificity.\n",
        "4. f1 score: The F1-score combines these three metrics into one single metric that ranges from 0 to 1 and it takes into account both Precision and Recall.\n",
        "5. Confusion matrix: This matrix tell us all the correctly clasified along with incorrectly classified labels in the form of a matrix hence easier to read.\n",
        "\n",
        "All of the above were kept into account while chosing the final classifier and their results were compared. SVM got the highest score for them all and hence was chose to finally train the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "1. 2487 audio files have been used in total out of which 1176 are outdoors and 1311 are indoors.\n",
        "2. Input features and output label conversion is done for all the files already explained earlier which is then followed by PCA to select only relevant input features.\n",
        "3. The total files are then divided into 70:30 raito for training and test data split. \n",
        "4. The 70% data is then used to train the classifier and the remaining 30% used to validate the classifier.\n",
        "\n",
        "All the code for feature extraction, label conversion and data split is already done in above sections and explained.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "pt=precision_score(yt_p,y_train)\n",
        "rt=recall_score(yt_p,y_train)\n",
        "f1t=f1_score(yt_p,y_train)\n",
        "mt=metrics.confusion_matrix(yt_p,y_train)\n",
        "\n",
        "\n",
        "pv=precision_score(yv_p,y_val)\n",
        "rv=recall_score(yv_p,y_val)\n",
        "f1v=f1_score(yv_p,y_val)\n",
        "mv=metrics.confusion_matrix(yv_p,y_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train),\"\\nTraining precision\",pt,\"\\nTraining recall\",rt,\"\\nTrianing f1 score\",f1t)\n",
        "print(\"Confusion Matrix for training period:\",mt,\"\\n\")\n",
        "\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val),\"\\nValidation precision\",pv,\"\\nValidation recall\",rv,\"\\nValidation f1 score\",f1v)\n",
        "print(\"Confusion Matrix for validation period:\",mv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvHoBSf8abW-",
        "outputId": "5dff5af8-a262-480d-995d-981e428b7117"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.7367816091954023 \n",
            "Training precision 0.7657550535077289 \n",
            "Training recall 0.7116022099447514 \n",
            "Trianing f1 score 0.7376861397479955\n",
            "Confusion Matrix for training period: [[638 197]\n",
            " [261 644]] \n",
            "\n",
            "Validation  Accuracy 0.6746987951807228 \n",
            "Validation precision 0.7014925373134329 \n",
            "Validation recall 0.6216931216931217 \n",
            "Validation f1 score 0.6591865357643758\n",
            "Confusion Matrix for validation period: [[269 100]\n",
            " [143 235]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(X_train,axis=0)\n",
        "sd=np.std(X_train,axis=0)\n",
        "mean1 = np.mean(X_val,axis=0)\n",
        "sd1=np.std(X_val,axis=0)\n",
        "X_train = (X_train-mean)/sd\n",
        "X_val  = (X_val-mean1)/sd1\n",
        "\n",
        "choice=\"Svc\"\n",
        "if choice==\"Rand\":\n",
        "  print(\"RandomForest:\")\n",
        "  model  = RandomForestClassifier(n_estimators=10)\n",
        "elif choice==\"Svc\":\n",
        "  print(\"SVC:\")\n",
        "  model  = svm.SVC(C=2)\n",
        "else:\n",
        "    print(\"KNN\")\n",
        "    model=KNeighborsClassifier(n_neighbors=50) \n",
        "\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "pt=precision_score(yt_p,y_train)\n",
        "rt=recall_score(yt_p,y_train)\n",
        "f1t=f1_score(yt_p,y_train)\n",
        "mt=metrics.confusion_matrix(yt_p,y_train)\n",
        "\n",
        "\n",
        "pv=precision_score(yv_p,y_val)\n",
        "rv=recall_score(yv_p,y_val)\n",
        "f1v=f1_score(yv_p,y_val)\n",
        "mv=metrics.confusion_matrix(yv_p,y_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train),\"\\nTraining precision\",pt,\"\\nTraining recall\",rt,\"\\nTrianing f1 score\",f1t)\n",
        "print(\"Confusion Matrix for training period:\",mt,\"\\n\")\n",
        "\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val),\"\\nValidation precision\",pv,\"\\nValidation recall\",rv,\"\\nValidation f1 score\",f1v)\n",
        "print(\"Confusion Matrix for validation period:\",mv)"
      ],
      "metadata": {
        "id": "BtruWxeq9eXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2661d5d-6fe5-4e85-ae45-a6768b1a9e3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC:\n",
            "Training Accuracy 0.7413793103448276 \n",
            "Training precision 0.7562425683709869 \n",
            "Training recall 0.7219069239500567 \n",
            "Trianing f1 score 0.7386759581881533\n",
            "Confusion Matrix for training period: [[654 205]\n",
            " [245 636]] \n",
            "\n",
            "Validation  Accuracy 0.6907630522088354 \n",
            "Validation precision 0.7283582089552239 \n",
            "Validation recall 0.6354166666666666 \n",
            "Validation f1 score 0.678720445062587\n",
            "Confusion Matrix for validation period: [[272  91]\n",
            " [140 244]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "After training different models and comparing their effeciency through the defined metrices SVM was found out to be the best.\n",
        "\n",
        "Both the classes were equally likely correctly predicted hence the classifier is not bisaed towards any one of them.\n",
        "\n",
        "The performace of the classifier was improved via normalizing the values of the input features for both training and validation dataset.\n",
        "\n",
        "Also increasing the cost parameter from 1 till 2 gave more accuracy, hence with a little higher cost of misclassification a better result was acheived.\n",
        "\n",
        "The scores of the best model i.e., SVM for predicting an audio as indoors or outdoors are as follows:\n",
        "\n",
        "SVC:\n",
        "\n",
        "Training Accuracy 0.7413793103448276 \n",
        "\n",
        "Training precision 0.7562425683709869 \n",
        "\n",
        "Training recall 0.7219069239500567 \n",
        "\n",
        "Trianing f1 score 0.7386759581881533\n",
        "\n",
        "Confusion Matrix for training period: \n",
        "\n",
        "[[654 205]\n",
        "\n",
        "[245 636]] \n",
        "\n",
        "Validation  Accuracy 0.6907630522088354\n",
        "\n",
        "Validation precision 0.7283582089552239 \n",
        "\n",
        "Validation recall 0.6354166666666666 \n",
        "\n",
        "Validation f1 score 0.678720445062587\n",
        "\n",
        "Confusion Matrix for validation period: \n",
        "\n",
        "[[272  91]\n",
        "\n",
        "[140 244]]\n"
      ]
    }
  ]
}